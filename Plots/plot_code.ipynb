{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd79ae75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Summary Table =====\n",
      "protocol  quality  avg_total_time_ms  success_count  total_queries  success_rate_%\n",
      "    Do53 Bottom50         975.701565             46             50            92.0\n",
      "    Do53    Top50         753.991446             50             50           100.0\n",
      "     DoH Bottom50        1343.934565             50             50           100.0\n",
      "     DoH    Top50         926.084037             50             50           100.0\n",
      "     DoT Bottom50        1164.095105             49             49           100.0\n",
      "     DoT    Top50         843.089805             50             50           100.0\n",
      "\n",
      "✅ All plots saved in: /Users/tejasmacipad/Desktop/final_CN_project/CN_Project/Report_2_new/plots_final_json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ---------------- CONFIGURATION ----------------\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "base_path = \"/Users/tejasmacipad/Desktop/final_CN_project/CN_Project/Report_2_new\"\n",
    "save_dir = \"./plots_final_json\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ---------------- FILE PATHS ----------------\n",
    "paths = {\n",
    "    \"Do53\": [f\"{base_path}/do53_log_top50.json\", f\"{base_path}/do53_log_top30003050.json\"],\n",
    "    \"DoH\": [f\"{base_path}/doh_log_top50.json\", f\"{base_path}/doh_log_top30003050.json\"],\n",
    "    \"DoT\": [f\"{base_path}/dot_log_top50.json\", f\"{base_path}/dot_log_top30003050.json\"],\n",
    "}\n",
    "\n",
    "# ---------------- LOADING FUNCTION ----------------\n",
    "def load_json_file(path, protocol):\n",
    "    \"\"\"Load JSON file and return DataFrame with protocol tag.\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"protocol\"] = protocol\n",
    "    return df\n",
    "\n",
    "# ---------------- LOAD ALL FILES ----------------\n",
    "dfs = []\n",
    "for proto, files in paths.items():\n",
    "    for fpath in files:\n",
    "        dfs.append(load_json_file(fpath, proto))\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# ---------------- CLEANING + NORMALIZATION ----------------\n",
    "# Map columns to consistent names\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"timestamp\": \"timestamp_utc\",\n",
    "        \"bytes_sent\": \"bytes_out\",\n",
    "        \"bytes_recv\": \"bytes_in\",\n",
    "        \"tcp_handshake_ms\": \"tcp_connect_ms\",\n",
    "        \"query_time_ms\": \"query_rtt_ms\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ensure numeric columns\n",
    "for col in [\"tcp_connect_ms\", \"tls_handshake_ms\", \"query_rtt_ms\", \"bytes_out\", \"bytes_in\", \"total_time_ms\"]:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Convert timestamp\n",
    "df[\"timestamp_utc\"] = pd.to_datetime(df[\"timestamp_utc\"], errors=\"coerce\")\n",
    "\n",
    "# ---------------- ADD QUALITY LABEL ----------------\n",
    "qualities = [\"Top50\", \"Bottom50\"]\n",
    "df[\"quality\"] = df.groupby(\"protocol\").cumcount().apply(lambda x: qualities[x // 50] if x // 50 < 2 else \"Extra\")\n",
    "\n",
    "# ✅ Remove rows labeled \"Extra\"\n",
    "df = df[df[\"quality\"] != \"Extra\"]\n",
    "\n",
    "# ---------------- 1️⃣ LATENCY DISTRIBUTION ----------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x=\"protocol\", y=\"total_time_ms\", hue=\"quality\", palette=\"Set2\")\n",
    "plt.title(\"Total DNS Resolution Time by Protocol and Website Group\")\n",
    "plt.ylabel(\"Total Time (ms)\")\n",
    "plt.xlabel(\"Protocol\")\n",
    "plt.savefig(f\"{save_dir}/1_latency_boxplot.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# ---------------- 2️⃣ BANDWIDTH ANALYSIS ----------------\n",
    "bw = (\n",
    "    df.groupby([\"protocol\", \"quality\"])[[\"bytes_out\", \"bytes_in\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "bw[\"total_bytes\"] = bw[\"bytes_out\"] + bw[\"bytes_in\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bw_melt = bw.melt(\n",
    "    id_vars=[\"protocol\", \"quality\"],\n",
    "    value_vars=[\"bytes_out\", \"bytes_in\", \"total_bytes\"],\n",
    "    var_name=\"Type\",\n",
    "    value_name=\"Bytes\",\n",
    ")\n",
    "sns.barplot(data=bw_melt, x=\"protocol\", y=\"Bytes\", hue=\"Type\", palette=\"coolwarm\")\n",
    "plt.title(\"Average Bandwidth Usage per Query (Top vs Bottom)\")\n",
    "plt.ylabel(\"Bytes\")\n",
    "plt.savefig(f\"{save_dir}/2_bandwidth_bar.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# ---------------- 3️⃣ SUCCESS RATE ----------------\n",
    "success_counts = (\n",
    "    df.groupby([\"protocol\", \"quality\", \"status\"]).size().reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    data=success_counts,\n",
    "    x=\"protocol\",\n",
    "    y=\"count\",\n",
    "    hue=\"status\",\n",
    "    palette=\"Paired\",\n",
    ")\n",
    "plt.title(\"Query Success vs Failure Rate (Top vs Bottom)\")\n",
    "plt.ylabel(\"Number of Queries\")\n",
    "plt.savefig(f\"{save_dir}/3_success_rate.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# ---------------- 4️⃣ TEMPORAL TREND ----------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "for proto in df[\"protocol\"].unique():\n",
    "    sub = df[df[\"protocol\"] == proto].sort_values(\"timestamp_utc\")\n",
    "    plt.plot(sub[\"timestamp_utc\"], sub[\"total_time_ms\"], label=proto, alpha=0.8)\n",
    "plt.title(\"DNS Latency Over Time\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Total Time (ms)\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{save_dir}/4_temporal_trend.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# ---------------- 5️⃣ SUMMARY TABLE ----------------\n",
    "summary = (\n",
    "    df.groupby([\"protocol\", \"quality\"])\n",
    "    .agg(\n",
    "        avg_total_time_ms=(\"total_time_ms\", \"mean\"),\n",
    "        success_count=(\"status\", lambda x: (x == \"SUCCESS\").sum()),\n",
    "        total_queries=(\"status\", \"count\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "summary[\"success_rate_%\"] = (summary[\"success_count\"] / summary[\"total_queries\"]) * 100\n",
    "\n",
    "print(\"\\n===== Summary Table =====\")\n",
    "print(summary.to_string(index=False))\n",
    "summary.to_csv(f\"{save_dir}/summary_stats.csv\", index=False)\n",
    "\n",
    "# ---------------- 6️⃣ CDF PLOT ----------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "for (proto, qual), sub in df.groupby([\"protocol\", \"quality\"]):\n",
    "    subset_sorted = sub[\"total_time_ms\"].dropna().sort_values().values\n",
    "    if len(subset_sorted) == 0:\n",
    "        continue\n",
    "    yvals = np.arange(len(subset_sorted)) / len(subset_sorted)\n",
    "    plt.plot(subset_sorted, yvals, label=f\"{proto}-{qual}\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Total Time (ms)\")\n",
    "plt.ylabel(\"Cumulative Probability\")\n",
    "plt.title(\"CDF of DNS Lookup Latency (Top vs Bottom)\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.savefig(f\"{save_dir}/6_latency_cdf.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\n✅ All plots saved in: {os.path.abspath(save_dir)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8f7ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Average Metrics per Protocol and Quality =====\n",
      "\n",
      "protocol  quality  tcp_handshake_ms  tls_handshake_ms  query_time_ms  total_time_ms  bytes_sent  bytes_recv  total_bytes  query_size_bytes  response_size_bytes\n",
      "    Do53 Bottom50              0.00              0.00         997.06         997.06       33.70       89.04       122.74             33.70                89.04\n",
      "    Do53    Top50              0.00              0.00         753.99         753.99       34.76       87.48       122.24             34.76                87.48\n",
      "     DoH Bottom50             25.43             40.31        1300.13        1366.27     1261.40     2202.04      3463.44            224.70               191.52\n",
      "     DoH    Top50             69.33             34.41         821.87         926.08     1263.52     2188.36      3451.88            225.76               184.68\n",
      "     DoT Bottom50             51.01             41.05        1071.65        1164.10      879.10     2013.29      2892.39             33.55                97.14\n",
      "     DoT    Top50             55.20             37.22         750.25         843.09      881.56     1995.88      2877.44             34.78                88.44\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ---------------- CONFIGURATION ----------------\n",
    "base_path = \"/Users/tejasmacipad/Desktop/final_CN_project/CN_Project/Report_2_new\"\n",
    "\n",
    "# ---------------- FILE PATHS ----------------\n",
    "paths = {\n",
    "    \"Do53\": [f\"{base_path}/do53_log_top50.json\", f\"{base_path}/do53_log_top30003050.json\"],\n",
    "    \"DoH\": [f\"{base_path}/doh_log_top50.json\", f\"{base_path}/doh_log_top30003050.json\"],\n",
    "    \"DoT\": [f\"{base_path}/dot_log_top50.json\", f\"{base_path}/dot_log_top30003050.json\"],\n",
    "}\n",
    "\n",
    "# ---------------- LOAD FILES ----------------\n",
    "def load_json_file(path, protocol, quality):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"protocol\"] = protocol\n",
    "    df[\"quality\"] = quality\n",
    "    # Only first 50 queries\n",
    "    df = df.head(50)\n",
    "    return df\n",
    "\n",
    "dfs = []\n",
    "for proto, files in paths.items():\n",
    "    dfs.append(load_json_file(files[0], proto, \"Top50\"))\n",
    "    dfs.append(load_json_file(files[1], proto, \"Bottom50\"))\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# ---------------- ENSURE NUMERIC FIELDS ----------------\n",
    "numeric_cols = [\n",
    "    \"tcp_handshake_ms\",\n",
    "    \"tls_handshake_ms\",\n",
    "    \"query_time_ms\",\n",
    "    \"total_time_ms\",\n",
    "    \"bytes_sent\",\n",
    "    \"bytes_recv\",\n",
    "    \"query_size_bytes\",\n",
    "    \"response_size_bytes\",\n",
    "]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Compute total bytes if not already present\n",
    "if \"total_bytes\" not in df.columns:\n",
    "    df[\"total_bytes\"] = df[\"bytes_sent\"] + df[\"bytes_recv\"]\n",
    "\n",
    "# ---------------- COMPUTE BASIC METRICS ----------------\n",
    "summary = (\n",
    "    df.groupby([\"protocol\", \"quality\"])\n",
    "    .agg({\n",
    "        \"tcp_handshake_ms\": \"mean\",\n",
    "        \"tls_handshake_ms\": \"mean\",\n",
    "        \"query_time_ms\": \"mean\",\n",
    "        \"total_time_ms\": \"mean\",\n",
    "        \"bytes_sent\": \"mean\",\n",
    "        \"bytes_recv\": \"mean\",\n",
    "        \"total_bytes\": \"mean\",\n",
    "        \"query_size_bytes\": \"mean\",\n",
    "        \"response_size_bytes\": \"mean\"\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Round for neatness\n",
    "summary = summary.round(2)\n",
    "\n",
    "# ---------------- DISPLAY ----------------\n",
    "print(\"\\n===== Average Metrics per Protocol and Quality =====\\n\")\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccaf423d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average bandwidth (kbps) per protocol & quality:\n",
      "\n",
      "protocol  quality  bandwidth_kbps\n",
      "    Do53 Bottom50            1.49\n",
      "    Do53    Top50            1.94\n",
      "     DoH Bottom50           34.44\n",
      "     DoH    Top50           44.19\n",
      "     DoT Bottom50           30.00\n",
      "     DoT    Top50           39.80\n",
      "\n",
      "Saved plot to: /Users/tejasmacipad/Desktop/final_CN_project/CN_Project/Report_2_new/plots_final_json/avg_bandwidth_kbps.png\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "\n",
    "base_path = \"/Users/tejasmacipad/Desktop/final_CN_project/CN_Project/Report_2_new\"\n",
    "save_dir = \"./plots_final_json\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "paths = {\n",
    "    \"Do53\": [f\"{base_path}/do53_log_top50.json\", f\"{base_path}/do53_log_top30003050.json\"],\n",
    "    \"DoH\":  [f\"{base_path}/doh_log_top50.json\",  f\"{base_path}/doh_log_top30003050.json\"],\n",
    "    \"DoT\":  [f\"{base_path}/dot_log_top50.json\",  f\"{base_path}/dot_log_top30003050.json\"],\n",
    "}\n",
    "\n",
    "# ---------------- LOAD (first 50 per file only) ----------------\n",
    "def load_json_file(path, protocol, quality):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"protocol\"] = protocol\n",
    "    df[\"quality\"] = quality\n",
    "    # take at most first 50 entries (ignore extras)\n",
    "    return df.head(50)\n",
    "\n",
    "dfs = []\n",
    "for proto, files in paths.items():\n",
    "    dfs.append(load_json_file(files[0], proto, \"Top50\"))\n",
    "    dfs.append(load_json_file(files[1], proto, \"Bottom50\"))\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# ---------------- NORMALIZE NAMES & NUMERIC ----------------\n",
    "# ensure total_bytes exists\n",
    "if \"total_bytes\" not in df.columns:\n",
    "    # prefer bytes_sent/bytes_recv or bytes_out/bytes_in if present\n",
    "    if \"bytes_sent\" in df.columns and \"bytes_recv\" in df.columns:\n",
    "        df[\"total_bytes\"] = pd.to_numeric(df[\"bytes_sent\"], errors=\"coerce\") + pd.to_numeric(df[\"bytes_recv\"], errors=\"coerce\")\n",
    "    elif \"bytes_out\" in df.columns and \"bytes_in\" in df.columns:\n",
    "        df[\"total_bytes\"] = pd.to_numeric(df[\"bytes_out\"], errors=\"coerce\") + pd.to_numeric(df[\"bytes_in\"], errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"total_bytes\"] = np.nan\n",
    "\n",
    "# ensure total_time_ms exists (use total_time_ms or compute from pieces)\n",
    "if \"total_time_ms\" not in df.columns:\n",
    "    # fallbacks (not expected) - set NaN\n",
    "    df[\"total_time_ms\"] = np.nan\n",
    "\n",
    "# coerce numeric\n",
    "df[\"total_bytes\"]    = pd.to_numeric(df[\"total_bytes\"], errors=\"coerce\")\n",
    "df[\"total_time_ms\"]  = pd.to_numeric(df[\"total_time_ms\"], errors=\"coerce\")\n",
    "\n",
    "# drop rows with invalid or zero time or bytes (can't compute bandwidth)\n",
    "df = df.dropna(subset=[\"total_bytes\", \"total_time_ms\"])\n",
    "df = df[df[\"total_time_ms\"] > 0]\n",
    "if df.empty:\n",
    "    raise SystemExit(\"No valid rows (total_bytes / total_time_ms) to compute bandwidth.\")\n",
    "\n",
    "# ---------------- PER-QUERY BANDWIDTH (kbps) ----------------\n",
    "# bytes/sec = total_bytes / (total_time_ms / 1000)\n",
    "# kilobits/sec = (bytes/sec * 8) / 1000 = total_bytes * 8 / total_time_ms\n",
    "df[\"bandwidth_kbps\"] = (df[\"total_bytes\"] * 8.0) / df[\"total_time_ms\"]\n",
    "\n",
    "# ---------------- GROUP & AVERAGE ----------------\n",
    "agg = df.groupby([\"protocol\", \"quality\"])[\"bandwidth_kbps\"].mean().reset_index()\n",
    "agg[\"bandwidth_kbps\"] = agg[\"bandwidth_kbps\"].round(2)\n",
    "\n",
    "# ---------------- PLOT ----------------\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=agg, x=\"protocol\", y=\"bandwidth_kbps\", hue=\"quality\", palette=\"Set2\")\n",
    "plt.ylabel(\"Average Bandwidth (kbps)\")\n",
    "plt.xlabel(\"Protocol\")\n",
    "plt.title(\"Average load (kilobits/sec) per Query — mean over samples\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "plt.legend(title=\"Website group\")\n",
    "plt.tight_layout()\n",
    "outpath = os.path.join(save_dir, \"avg_bandwidth_kbps.png\")\n",
    "plt.savefig(outpath, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# ---------------- PRINT TABLE ----------------\n",
    "print(\"\\nAverage bandwidth (kbps) per protocol & quality:\\n\")\n",
    "print(agg.to_string(index=False))\n",
    "\n",
    "print(f\"\\nSaved plot to: {os.path.abspath(outpath)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe116b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
